# üé¨ Movie Recommendation System - Content-Based Filtering

# Step 1: Import required libraries
import pandas as pd
import numpy as np
import ast
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Step 2: Load datasets
movies = pd.read_csv('tmdb_5000_movies.csv') #please use the given dataset in repositry
credits = pd.read_csv('tmdb_5000_credits.csv')

# Step 3: Merge the two datasets on 'title'
movies = movies.merge(credits, on='title')

# Step 4: Select required columns and rename for clarity
movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]

# Step 5: Drop missing values
movies.dropna(inplace=True)

# Step 6: Preprocess JSON-like columns using ast.literal_eval
def extract_names(obj):
    return [item['name'] for item in ast.literal_eval(obj)]

def extract_top_cast(obj):
    return [item['name'] for item in ast.literal_eval(obj)[:3]]

def extract_director(obj):
    for item in ast.literal_eval(obj):
        if item['job'] == 'Director':
            return item['name']
    return ''

# Apply extraction functions
movies['genres'] = movies['genres'].apply(extract_names)
movies['keywords'] = movies['keywords'].apply(extract_names)
movies['cast'] = movies['cast'].apply(extract_top_cast)
movies['crew'] = movies['crew'].apply(extract_director)

# Step 7: Clean overview (tokenize words) and combine all into 'tags'
movies['overview'] = movies['overview'].apply(lambda x: x.split())

# Convert crew (director) to list for consistency
movies['crew'] = movies['crew'].apply(lambda x: [x] if isinstance(x, str) else [])

# Combine all relevant text features
movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']

# Create new dataframe with only required columns
new_df = movies[['movie_id', 'title', 'tags']]

# Convert list of words into single string
new_df['tags'] = new_df['tags'].apply(lambda x: " ".join(x))

# Convert all text to lowercase
new_df['tags'] = new_df['tags'].apply(lambda x: x.lower())

# Step 8: Text Vectorization using CountVectorizer
cv = CountVectorizer(max_features=5000, stop_words='english')
vectors = cv.fit_transform(new_df['tags']).toarray()

# Step 9: Compute cosine similarity matrix
similarity = cosine_similarity(vectors)

# Step 10: Recommendation function
def recommend(movie):
    movie = movie.lower()
    if movie not in new_df['title'].str.lower().values:
        print("‚ùå Movie not found in the dataset.")
        return
    
    # Get index of the movie
    idx = new_df[new_df['title'].str.lower() == movie].index[0]
    
    # Get similarity scores
    distances = list(enumerate(similarity[idx]))
    
    # Sort by similarity and take top 5
    movies_list = sorted(distances, key=lambda x: x[1], reverse=True)[1:6]
    
    print(f"üé• Top 5 movies similar to '{movie.title()}':")
    for i in movies_list:
        print(new_df.iloc[i[0]].title)

# üß™ Example Usage:
recommend("Avatar")
